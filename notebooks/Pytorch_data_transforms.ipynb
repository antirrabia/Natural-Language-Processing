{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132f54a8-407c-46e4-9156-8574ab718410",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Template\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "torch.use_deterministic_algorithms(True)\n",
    "### Template End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d088d18-b179-40c4-8031-cb323cf27aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e534551d-2045-403f-ace9-79d546950f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "\n",
    "from torch.optim import lr_scheduler \n",
    "from torchvision import datasets, models, transforms \n",
    "\n",
    "\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from pathlib import Path\n",
    "\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "696f0ac9-9e8d-4e79-bcdc-a82f0e63a7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2717f734-6d75-41f5-84e2-a52365a749a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '/home/antirrabia/Documents/speriments/torch_datasets/bees_ants/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef573c38-786a-4859-b56c-29630aeb268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dir = Path(ddir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d9637-c2eb-444d-b4e2-43a8121e353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = {k: datasets.ImageFolder( w_dir + k, data_transforms[k]) for k in ['train', 'val']}\n",
    "data_loaders = {k: torch.utils.data.DataLoader( img_data[k] , batch_size=8, shuffle=True ) for k in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d62724f-8719-4950-953b-a034169ce9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Template\n",
    "\n",
    "data_transformers = {\n",
    "    'train': transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
    "        ]\n",
    "    ),\n",
    "    'val': transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "img_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in ['train', 'val']}\n",
    "dloaders = {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True) for k in ['train', 'val']}\n",
    "    \n",
    "dset_sizes = {x: len(img_data[x]) for x in ['train', 'val']}\n",
    "\n",
    "classes = img_data['train'].classes\n",
    "\n",
    "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fc4297-c769-4871-b35b-fddc00ddc9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423066d-7a33-4121-b782-ccff43c28807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "img_data = { k:   for k in ['train', 'val'] }\n",
    "d_loader = { k:   for k in ['train', 'val'] }\n",
    "\n",
    "img_data = { k: datasets.ImageFolder(os.path.join(ddir, k), data_transforms[k]) for k in ['train', 'val'] }\n",
    "dloader = { k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True) for k in ['train', 'val'] }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ffa4e-d7e8-42a9-a186-e2e25225a9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
